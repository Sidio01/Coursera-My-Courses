from icecream import ic


# Глава 1. Знакомство с алгоритмами

# Бинарный поиск это алгоритм; на входе он получает отсортированный список элементов (позднее я объясню, почему он должен быть отсортирован). Если элемент, который вы ищете, присутствует в списке, то бинарный поиск возвращает ту позицию, в которой он был найден. В противном случае бинарный поиск возвращает null. Каждую итерацию мы отсекаем половину списка и так до тех пор, пока не будет найден искомый элемент.
# Сложность бинарного поиска - О(log2 n) - логарифмическое время
# Сложность простого поиска - О(n) - линейное время

def binary_search(list, item):
    low = 0
    high = len(list) - 1

    while low <= high:
        mid = low + high
        guess = list[mid]
        if guess == item:
            return mid
        if guess > item:
            high = mid - 1
        else:
            low = mid + 1
    return None

my_list = [1, 3, 5, 7, 9]
ic(binary_search(my_list, 5))
ic(binary_search(my_list, -1))

# О-большое определяет время выполнения в худшем случае
# Виды О-большого:
# 1) О(log n) - логарифмическое время. Пример: бинарный поиск.
# 2) O(n) - линейное время. Пример: простой поиск
# 3) O(n * log n) - Пример: эффективные алгоритмы сортировки (быстрая сортировка)
# 4) O(n**2) - Пример: медленные алгоритмы сортировки (сортировка выбором)
# 5) O(n!) - факториальное время. Пример: очень медленные алгоритмы (задача о коммивояжере)
# 6) O(c) - константное время, где с - константа.

# Шпаргалка к главе 1
# - Бинарный поиск работает намного быстрее простого.
# - Время выполнения O(log п) быстрее О(п), а с увеличением размера списка, в котором ищется значение, оно становится намного быстрее.
# - Скорость алгоритмов не измеряется в секундах.
# - Время выполнения алгоритма описывается ростом количества операций.
# - Время выполнения алгоритмов выражается как "О-большое".


# Глава 2. Сортировка выбором

#             Массивы     Связанные списки
# Чтение      O(1)        O(n)
# Вставка     O(n)        O(1)
# Удаление    O(n)        O(1)

# Сортировка выбором - алгоритм, предполагающий создание дополнительного пустого списка и заполнение его посредством итерации по изначальному списку и нахождению в нем минимального элемента.
# Сложность алгоритма - O(0.5 * n**2), из-за прохождения списка из n элементов n раз с уменьшением количества элементов в списке на 1.

def find_smallest(arr):
    smallest = arr[0]
    smallest_index = 0
    for i in range(1, len(arr)):
        if arr[i] < smallest:
            smallest = arr[i]
            smallest_index = i
    return smallest_index

def selection_sort(arr):
    new_arr = []
    for i in range(len(arr)):
        smallest = find_smallest(arr)
        new_arr.append(arr.pop(smallest))
    return new_arr

my_list2 = [5, 3, 6, 2, 10]
ic(selection_sort(my_list2))

# Шпаргалка к главе 2
# - Память компьютера напоминает огромный шкаф с ящиками.
# - Если вам потребуется сохранить набор элементов, воспользуйтесь массивом или списком.
# - В массиве все элементы хранятся в памяти рядом друг с другом.
# - В списке элементы распределяются в произвольных местах памяти, при этом в одном элементе хранится адрес следующего элемента.
# - Массивы обеспечивают быстрое чтение.
# - Списки обеспечивают быструю вставку и выполнение.
# - Все элементы массива должны быть однотипными (только целые числа, только вещественные числа и т. д.).


# Глава 3. Рекурсия

# Псевдокод представляет собой высокоуровневое описание решаемой задачи . Он записывается в форме, похожей на программный код, но в большей степени напоминает естественный язык.

# Рекурсия - вызов функции самой себя. Чтобы не возник бесконечный цикл необходимо предусмотреть базовый (возврат значения) и рекурсивный случаи (запуск нового выполнения функции внутри изначальной).

# Рекурсия применяется тогда, когда решение становится более понятным. Применение рекурсии не ускоряет работу программы: более того, решение с циклами иногда работает быстрее. Мне нравится одна цитата Ли Колдуэлла с сайта Stack Overlow: "циклы могут ускорить работу программы . Рекурсия может ускорить работу программиста. Выбирайте, что важнее в вашей ситуации!"

# Стек вызовов - простая структура данных, предусматривающая запись и извлечение элементов. Концепция стека вызовов играет важную роль в программировании вообще; кроме того, ее важно понимать при использовании рекурсии.
# Когда вы вызываете функцию из другой функции, вызывающая функция приостанавливается в частичоо завершеноом состоянии. Все значения переменных этой функции остаются в памяти. А когда выполнение вложенной функции будет завершено, вы вернетесь к изначальной функции и продолжите ее выполнение с того места, где оно прервалось.
# Этот стек, в котором сохранялись переменные разных функций, называется стеком вызовов.

def fact(x):
    if x == 1:
        return 1
    else:
        return x * fact(x-1)

ic(fact(4))

# Стек удобен, но у него есть своя цена: сохранение всей промежуточной информации может привести к значительным затратам памяти. Каждый вызов функции занимает не много памяти, но если стек станет слишком высоким, это будет означать, что ваш компьютер сохраняет информацию по очень многим вызовам. На этой стадии есть два варианта:
# - Переписать код с использованием цикла.
# - Иногда можно воспользоваться так называемой хвостовой рекурсией. Это непростая тема, которая выходит за рамки книги. Вдобавок она поддерживается далеко не во всех языках .

# Шпаргалка к главе 3
# - Когда функция вызывает саму себя, это называется рекурсией.
# - В каждой рекурсивной функции должно быть два случая: базовый и рекурсивный .
# - Стек поддерживает две операции: занесение и извлечение элементов.
# - Все вызовы функций сохраняются в стеке вызовов.
# - Если стек вызовов станет очень большим, он займет слишком много памяти.


# Глава 4. Быстрая сортировка

# Cтратегия "разделяй и властвуй"! Алгоритмы на базе этой стратегии являются рекурсивными.
# Решение задачи методом "разделяй и властвуй" состоит из двух шагов:
# 1. Сначала определяется базовый случай. Это должен быть простейший случай из всех возможных.
# 2. Задача делится или сокращается до тех пор, пока не будет сведена к базовому случаю.

# СОВЕТ
# Когда вы пишете рекурсивную функцию, в которой задействован массив, базовым случаем часто оказывается пустой массив или массив из одного элемента. Если вы не знаете, с чего начать, - начните с этого.

# В функциональных языках программирования отсутствуют циклы, поэтому очень широко применяется рекурсия


def sum_list(arr):
    if len(arr) == 1:
        return arr[0]
    else:
        return arr[0] + sum_list(arr[1:])


def len_list(arr):
    if len(arr) == 1:
        return 1
    else:
        return 1 + len_list(arr[1:])


def find_largest(arr):
    largest = arr[0]
    if len(arr) == 1:
        return largest
    elif len(arr) == 2:
        next_element = arr[1]
        if next_element > largest:
            return next_element
        else:
            return largest
    else:
        sub_largest = find_largest(arr[1:])
        if sub_largest > largest:
            return sub_largest
        else:
            return largest


# def find_max(list):
#     if len(list) == 2:
#         return list[0] if list[0] > list[1] else list[1]
#     sub_max = find_max(list[1:])
#     return list[0] if list[0] > sub_max else sub_max


my_list3 = [2, 4, 8, 6, 3]
ic(sum_list(my_list3))
ic(len_list(my_list3))
ic(find_largest(my_list3))

# Быстрая сортировка. Как отсортировать подмассивы? Базовый случай быстрой сортировки уже знает, как сортировать массивы из двух элементов (левый подмассив) и пустые массивы (правый подмассив). Следовательно, если применить алгоритм быстрой сортировки к двум подмассивам, а затем объединить результаты, получится отсортированный массив.

# Чтобы отсортировать массивы из трех элементов следует:
# 1. Выбрать опорный элемент.
# 2. Разделить массив на два подмассива: элементы, меньшие опорного, и элементы, большие опорного.
# 3. Рекурсивно применить быструю сортировку к двум подмассивам.

def quicksort(arr):
    if len(arr) < 2:
        return arr
    else:
        pivot = arr[0]
        less = [i for i in arr[1:] if i <= pivot]
        greater = [i for i in arr[1:] if i > pivot]
        return quicksort(less) + [pivot] + quicksort(greater)

my_list4 = [3, 6, 1, 2, 8, 7, 9, 4, 5, 10]
ic(quicksort(my_list4))

# Алгоритм быстрой сортировки уникален тем, что его скорость зависит от выбора опорного элемента. Сложность O(n * log n). В худшем случае быстрая сортировка работает за время О(n**2).
# В указании сложности алгоритма обычно константа игнорируется, потому что если два алгоритма имеют разное время «О-большое~, она роли не играет.
# Однако в некоторых случаях константа может иметь значение. Один из примеров такого рода - быстрая сортировка и сортировка слиянием. У быстрой сортировки константа меньше, чем у сортировки слиянием, поэтому, несмотря на то что оба алгоритма характеризуются временем О(n * log n), быстрая сортировка работает быстрее. А на практике быстрая сортировка работает быстрее, потому что средний случай встречается намного чаще худшего.

# Шпаргалка к главе 4
# - Стратегия "разделяй и властвуй" основана на разбиении задачи на уменьшающиеся фрагменты. Если вы используете стратегию "разделяй и властвуй" со списком, то базовым случаем, скорее всего, является пустой массив или массив из одного элемента.
# - Если вы реализуете алгоритм быстрой сортировки, выберите в качестве опорного случайный элемент. Среднее время выполнения быстрой сортировки составляет О(n * log n)!
# - Константы в "О-большом" иногда могут иметь значение . Именно по этой причине быстрая сортировка быстрее сортировки слиянием.
# - При сравнении простой сортировки с бинарной константа почти никогда роли не играет, потому что O(log n) слишком сильно превосходит О(n) по скорости при большом размере списка.


# Глава 5. Хеш-таблицы.

# Хеш-функция представляет собой функцию, которая получает строку 1 и возвращает число:

# В научной терминологии говорят, что хеш-функция "отображает строки на числа". Можно подумать, что найти закономерности получения чисел для подаваемых на вход строк невозможно. Однако хеш-функция должна соответствовать некоторым требованиям:
# 1) Она должна быть последовательной. Допустим, вы передали ей строку "апельсины" и получили 4. Это значит, что каждый раз в будущем, передавая ей строку "апельсины", вы будете получать 4. Без этого хештаблица бесполезна.
# 2) Разным словам должны соответствовать разные числа. Например, хешфункция, которая возвращает 1 для каждого полученного слова, никуда не годится. В идеале каждое входное слово должно отображаться на свое число.

# Хеш-функция сообщает, где хранится цена, и вам вообще не нужно ничего искать! Такое решение работает, потому что:
# 1) Хеш-функция неизменно связывает название с одним индексом. Каждый раз, когда она вызывается для строки "авокадо", вы получаете обратно одно и то же число. При первом вызове этой функции вы узнаете, где следует сохранить цену авокадо, а при последующих вызовах она сообщает, где взять эту цену.
# 2) Хеш-функция связывает разные строки с разными индексами. "Авокадо" связывается с индексом 4, а "молоко" - с индексом О. Для каждой строки находится отдельная позиция массива, в которой сохраняется цена этого товара.
# 3) Хеш-функция знает размер массива и возвращает только действительные индексы. Таким образом, если длина массива равна 5 элементам, хеш-функция не вернет 100, потому что это значение не является действительным индексом в массиве.

# Свяжите воедино хеш-функцию и массив, и вы получите структуру данных, которая называется хеш-таблицей. Хеш-таблица станет первой изученной вами структурой данных, с которой связана дополнительная логика. Массивы и списки напрямую отображаются на адреса памяти, но хеш-таблицы устроены более умно. Они определяют место хранения элементов при помощи хеш-функций.

# Хеш-таблицы также известны под другими названиями:  "ассоциативные массивы" , "словари", "отображения", "хешкарты" или просто "хеши". Хеш-таблицы исключительно быстро работают! Обращение к элементу массива происходит мгновенно. А хеш-таблицы используют массивы для хранения данных, поэтому при обращении к элементам они не уступают массивам .

my_dict = {}
my_dict['tom'] = 'yes'
ic(my_dict)
ic(my_dict.get('bob'))

# Функция get возвращает значение , если ключ "tom" присутствует в хеш-таблице. В противном случае возвращается None. С помощью этой функции можно проверить присутствует ли ключ в хеш-таблице.

# Шпаргалка 1 к главе 5
# Хеши хорошо подходят для решения следующих задач:
# - моделирование отношений между объектами;
# - устранение дубликатов;
# -кэширование/запоминание данных вместо выполнения работы на сервере.

# Выбор хеш-функции действительно важен. Хеш-функция, отображающая все ключи на один элемент массива, никуда не годится. В идеале хеш-функция должна распределять ключи равномерно по всему хешу;
# Если связанные списки становятся слишком длинными, работа с хеш-таблицей сильно замедляется. Но они не станут слишком длинными при использовании хорошей хеш-функции!

# Быстродействие хеш-таблиц
            # Средний случай      Худший случай
# Поиск       O(1)                O(n)
# Вставка     O(1)                O(n)
# Удаление    O(1)                O(n)

# В среднем хеш-таблицы выполняют любые операции за время O(1). Время О(1) называется постоянным. Оно не означает, что операции выполняются мгновенно; просто время остается постоянным независимо от размера хеш-таблицы.
# При поиске хеш-таблицы не уступают в скорости массивам (получение значения по индексу) . А при вставке и удалении они так же быстры, как и связанные списки. Получается, что они взяли лучшее от обеих структур! Но в худшем случае хеш-таблицы медленно выполняют все эти операции, поэтому очень важно избегать худшего случая быстродействия при работе с хеш-таблицами. А для этого следует избегать коллизий. Для предотвращения коллизий необходимы:
# - низкий коэффициент заполнения;
# - хорошая хеш-функция .

# Коэффициент заполнения хеш-таблицы вычисляется по простой формуле - количество элементов в хеш-таблице / общее количество элементов. Коэффициент заполнения больше 1 означает, что количество товаров превышает количество элементов в массиве. С ростом коэффициента заполнения в хеш-таблицу приходится добавлять новые элементы, то есть изменять ее размер . Представим, что эта хеш-таблица приближается к заполнению. Хеш-таблицу необходимо расширить. Расширение начинается с создания нового массива большего размера. Обычно в таком случае создается массив вдвое большего размера.
# С меньшим коэффициентом загрузки число коллизий уменьшается, и ваша таблица начинает работать более эффективно. Хорошее приближенное правило:
# изменяйте размер хеш-таблицы, когда коэффициент заполнения превышает 0,7. Но ведь на изменение размеров уходит много времени, скажете вы, и будете абсолютно правы! Да, изменение размеров требует значительных затрат ресурсов, поэтому оно не должно происходить слишком часто. В среднем хеш-таблицы работают за время О(1) даже с изменением размеров.

# Шпаргалка 2 к главе 5
# Вам почти никогда не придется реализовать хеш-таблицу самостоятельно. Язык программирования, который вы используете, должен предоставить необходимую реализацию. Вы можете пользоваться хеш-таблицами Python, и при этом вам будет обеспечена производительность среднего случая: постоянное время.
# Хеш-таблицы чрезвычайно полезны, потому что они обеспечивают высокую скорость операций и позволяют по-разному моделировать данные. Возможно, вскоре выяснится, что вы постоянно используете их в своей работе.
# - Хеш-таблица создается объединением хеш-функции с массивом.
# - Коллизии нежелательны. Хеш -функция должна свести количество коллизий к минимуму.
# - Хеш-таблицы обеспечивают очень быстрое выполнение поиска, вставки и удаления.
# - Хеш-таблицы хорошо подходят для моделирования отношений между объектами.
# - Как только коэффициент заполнения превышает 0,7, пора изменять размер хеш-таблицы.
# - Хеш-таблицы используются для кэширования данных (например, на веб-серверах).
# - Хеш-таблицы хорошо подходят для обнаружения дубликатов.


# Глава 6. Поиск в ширину.

# Алгоритм для решения задачи поиска кратчайшего пути называется поиском в ширину.
# Чтобы найти кратчайший путь следует выполнить два шага:
# 1. Смоделировать задачу в виде графа.
# 2. Решить задачу методом поиска в ширину.

# Граф моделирует набор связей между разными объектами. Каждый граф состоит из узлов и ребер. Узел может быть напрямую соединен с несколькими другими узлами. Эти узлы называются соседями.

# Поиск в ширину также относится к категории алгоритмов поиска, но этот алгоритм работает с графами. Он помогает ответить на вопросы двух типов:
# тип 1: существует ли путь от узла А к узлу В?
# тип 2: как выглядит кратчайший путь от узла А к узлу В?

# Связи первого уровня предпочтительнее связей второго уровня, связи второго уровня предпочтительнее связей третьего уровня и т. д. Отсюда следует, что поиск по контактам второго уровня не долже н производиться, пока вы не будете полностью уверены в том, что среди связей первого уровня нет необходимого объекта.

# Поиск в ширину находит не только путь из А в В, но и кратчайший путь. Обратите внимание: это условие выполняется только в том случае, если поиск осуществляется в порядке добавления объектов. Следовательно, проверять связи нужно в порядке их добавления. Для операций такого рода существует специальная структура данных, которая называется очередью.

# Очереди чем-то похожи на стеки: вы не можете обращаться к произвольным элементам очереди. Вместо этого поддерживаются всего две операции: постановка в очередь и извлечение из очереди.

# Если вы поставите в очередь два элемента, то элемент, добавленный первым, будет извлечен из очереди раньше второго. 
# Очередь относится к категории структур данных FIFO: First In, First Out («первым вошел, первым вышел»). А стек принадлежит к числу структур данных LIFO: Last In, First Out («последним пришел , первым вышел»).

# Для начала необходимо реализовать граф на программном уровне. Граф состоит из нескольких узлов. И каждый узел соединяется с соседними узлами. Как выразить отношение типа "вы ---> боб"? К счастью, вам уже известна структура данных, способная выражать отношения: хеш-таблица! Вспомните: хеш-таблица связывает ключ со значением. В данном случае узел должен быть связан со всеми его соседями.

graph = {}
graph['you'] = ['alice', 'bob', 'claire']
graph['bob'] = ['anuj', 'peggy']
graph['alice'] = ['peggy']
graph['claire'] = ['thom', 'jonny']
graph['anuj'] = []
graph['peggy'] = []
graph['thom'] = []
graph['jonny'] = []

# В Python для создания двусторонней очереди (дека) используется функция deque:

from collections import deque

def person_is_seller(name):
    return name[-1] == 'm'

def search_mango_seller(name):
    search_queue = deque()
    search_queue += graph[name]
    searched = []
    while search_queue:
        person = search_queue.popleft()
        if not person in searched:
            if person_is_seller(person):
                print(person + ' is mango seller!')
                return True
            else:
                search_queue += graph[person]
                searched.append(person)
    return False

ic(search_mango_seller('you'))

# Время выполнения. Если поиск продавца манго был выполнен по всей сети, значит, вы прошли по каждому ребру (напомню: ребром называется соединительная линия или линия со стрелкой, ведущая от одного человека к другому). Таким образом, время выполнения составляет как минимум О( количество ребер).
# Также в программе должна храниться очередь поиска. Добавление одного человека в очередь выполняется за постоянное время : О(1). Выполнение операции для каждого человека потребует суммарного времени О(количество людей). Поиск в ширину выполняется за время О(количество людей + количество ребер), что обычно записывается в форме O(V+E) (V количество вершин ,Е - количество ребер).




# текущая страница - 149
# ответы к упражнениям - 275

