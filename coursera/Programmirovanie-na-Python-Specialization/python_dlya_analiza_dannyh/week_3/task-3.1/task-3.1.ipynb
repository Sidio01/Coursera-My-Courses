{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом практическом задании мы поработаем с алгоритмом линейной регрессии и нормализацией признаков. Для начала загрузите данные из файла `data.csv`, который содержит 100 признаков f1, f2, ..., f100 и целевую переменную target. Для загрузки данных используете функцию `read_csv` из библиотеки `pandas`. Выделите матрицу признаков и целевую переменную из загруженных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.979019</td>\n",
       "      <td>0.392456</td>\n",
       "      <td>1.195177</td>\n",
       "      <td>0.209349</td>\n",
       "      <td>-1.209435</td>\n",
       "      <td>0.868798</td>\n",
       "      <td>0.384209</td>\n",
       "      <td>-0.426571</td>\n",
       "      <td>-0.977939</td>\n",
       "      <td>-1.419877</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.587188</td>\n",
       "      <td>-0.612423</td>\n",
       "      <td>-0.281845</td>\n",
       "      <td>-0.625773</td>\n",
       "      <td>-0.907327</td>\n",
       "      <td>-0.800223</td>\n",
       "      <td>0.065892</td>\n",
       "      <td>0.271684</td>\n",
       "      <td>-0.201420</td>\n",
       "      <td>-45.587910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613518</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.238789</td>\n",
       "      <td>-0.071601</td>\n",
       "      <td>-0.080717</td>\n",
       "      <td>1.727543</td>\n",
       "      <td>-0.483886</td>\n",
       "      <td>0.635172</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>1.573987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059630</td>\n",
       "      <td>0.120031</td>\n",
       "      <td>0.399223</td>\n",
       "      <td>0.494030</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>0.652323</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>-1.556582</td>\n",
       "      <td>-0.370614</td>\n",
       "      <td>137.329473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444198</td>\n",
       "      <td>-0.535317</td>\n",
       "      <td>0.664927</td>\n",
       "      <td>-0.327017</td>\n",
       "      <td>1.935154</td>\n",
       "      <td>-1.776012</td>\n",
       "      <td>0.207803</td>\n",
       "      <td>0.126178</td>\n",
       "      <td>0.252569</td>\n",
       "      <td>0.889037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195482</td>\n",
       "      <td>1.384532</td>\n",
       "      <td>0.522251</td>\n",
       "      <td>-0.127655</td>\n",
       "      <td>-0.403076</td>\n",
       "      <td>-0.111509</td>\n",
       "      <td>-0.183150</td>\n",
       "      <td>0.977816</td>\n",
       "      <td>-1.171654</td>\n",
       "      <td>141.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.485186</td>\n",
       "      <td>-0.101987</td>\n",
       "      <td>0.817982</td>\n",
       "      <td>-0.846498</td>\n",
       "      <td>-0.660834</td>\n",
       "      <td>-0.073107</td>\n",
       "      <td>-0.247340</td>\n",
       "      <td>-0.775607</td>\n",
       "      <td>1.015937</td>\n",
       "      <td>-1.075737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753417</td>\n",
       "      <td>-0.403380</td>\n",
       "      <td>0.087974</td>\n",
       "      <td>-1.525572</td>\n",
       "      <td>2.404838</td>\n",
       "      <td>0.011863</td>\n",
       "      <td>0.994299</td>\n",
       "      <td>-2.152914</td>\n",
       "      <td>-0.213593</td>\n",
       "      <td>-65.882640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276582</td>\n",
       "      <td>-0.208468</td>\n",
       "      <td>0.185689</td>\n",
       "      <td>0.508608</td>\n",
       "      <td>-1.527168</td>\n",
       "      <td>-1.373403</td>\n",
       "      <td>-0.481766</td>\n",
       "      <td>-2.854627</td>\n",
       "      <td>1.868818</td>\n",
       "      <td>-1.179460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.985540</td>\n",
       "      <td>0.419706</td>\n",
       "      <td>-0.610858</td>\n",
       "      <td>0.209534</td>\n",
       "      <td>-0.538048</td>\n",
       "      <td>0.164295</td>\n",
       "      <td>-0.984655</td>\n",
       "      <td>-0.598438</td>\n",
       "      <td>-0.887770</td>\n",
       "      <td>-333.409221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.372648</td>\n",
       "      <td>-0.450202</td>\n",
       "      <td>-0.637809</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>1.193587</td>\n",
       "      <td>1.637212</td>\n",
       "      <td>1.178419</td>\n",
       "      <td>-0.047799</td>\n",
       "      <td>-1.285599</td>\n",
       "      <td>-1.671761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.657035</td>\n",
       "      <td>-1.615846</td>\n",
       "      <td>-0.404157</td>\n",
       "      <td>0.810027</td>\n",
       "      <td>-1.333148</td>\n",
       "      <td>1.419036</td>\n",
       "      <td>0.144310</td>\n",
       "      <td>1.040058</td>\n",
       "      <td>-1.298104</td>\n",
       "      <td>82.055263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-2.291293</td>\n",
       "      <td>0.441420</td>\n",
       "      <td>-0.080816</td>\n",
       "      <td>-0.258764</td>\n",
       "      <td>-0.278120</td>\n",
       "      <td>0.638957</td>\n",
       "      <td>0.748936</td>\n",
       "      <td>-0.893833</td>\n",
       "      <td>-0.435053</td>\n",
       "      <td>-3.232565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.421483</td>\n",
       "      <td>-1.478002</td>\n",
       "      <td>-0.518134</td>\n",
       "      <td>-2.248497</td>\n",
       "      <td>2.116012</td>\n",
       "      <td>-0.181734</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>-1.572231</td>\n",
       "      <td>-0.903293</td>\n",
       "      <td>65.950817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-0.735201</td>\n",
       "      <td>-2.426392</td>\n",
       "      <td>-0.716043</td>\n",
       "      <td>0.395799</td>\n",
       "      <td>-0.495878</td>\n",
       "      <td>0.307677</td>\n",
       "      <td>-1.890010</td>\n",
       "      <td>1.356583</td>\n",
       "      <td>-0.880754</td>\n",
       "      <td>-0.388243</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351073</td>\n",
       "      <td>1.798725</td>\n",
       "      <td>1.070365</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>-0.777371</td>\n",
       "      <td>0.388376</td>\n",
       "      <td>-3.007632</td>\n",
       "      <td>-0.009289</td>\n",
       "      <td>0.084168</td>\n",
       "      <td>77.147045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.288076</td>\n",
       "      <td>1.704102</td>\n",
       "      <td>0.505021</td>\n",
       "      <td>-1.820760</td>\n",
       "      <td>-0.345919</td>\n",
       "      <td>2.277086</td>\n",
       "      <td>2.042178</td>\n",
       "      <td>0.487775</td>\n",
       "      <td>-1.031966</td>\n",
       "      <td>2.394362</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.795643</td>\n",
       "      <td>-0.440259</td>\n",
       "      <td>0.731001</td>\n",
       "      <td>0.341660</td>\n",
       "      <td>0.733548</td>\n",
       "      <td>-2.074486</td>\n",
       "      <td>-0.766864</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>-0.423890</td>\n",
       "      <td>-13.136238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-1.375634</td>\n",
       "      <td>-0.345104</td>\n",
       "      <td>0.314339</td>\n",
       "      <td>1.282795</td>\n",
       "      <td>-1.835769</td>\n",
       "      <td>0.474633</td>\n",
       "      <td>1.243428</td>\n",
       "      <td>1.436368</td>\n",
       "      <td>1.178253</td>\n",
       "      <td>0.301407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456698</td>\n",
       "      <td>0.408136</td>\n",
       "      <td>2.369287</td>\n",
       "      <td>-0.502869</td>\n",
       "      <td>-0.756004</td>\n",
       "      <td>-0.822166</td>\n",
       "      <td>0.381353</td>\n",
       "      <td>0.464251</td>\n",
       "      <td>1.943529</td>\n",
       "      <td>1.627152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0   -1.979019  0.392456  1.195177  0.209349 -1.209435  0.868798  0.384209   \n",
       "1    0.613518  0.051946  0.238789 -0.071601 -0.080717  1.727543 -0.483886   \n",
       "2    0.444198 -0.535317  0.664927 -0.327017  1.935154 -1.776012  0.207803   \n",
       "3   -1.485186 -0.101987  0.817982 -0.846498 -0.660834 -0.073107 -0.247340   \n",
       "4    0.276582 -0.208468  0.185689  0.508608 -1.527168 -1.373403 -0.481766   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "120  0.372648 -0.450202 -0.637809  0.113971  1.193587  1.637212  1.178419   \n",
       "121 -2.291293  0.441420 -0.080816 -0.258764 -0.278120  0.638957  0.748936   \n",
       "122 -0.735201 -2.426392 -0.716043  0.395799 -0.495878  0.307677 -1.890010   \n",
       "123  1.288076  1.704102  0.505021 -1.820760 -0.345919  2.277086  2.042178   \n",
       "124 -1.375634 -0.345104  0.314339  1.282795 -1.835769  0.474633  1.243428   \n",
       "\n",
       "           f8        f9       f10  ...       f92       f93       f94  \\\n",
       "0   -0.426571 -0.977939 -1.419877  ... -1.587188 -0.612423 -0.281845   \n",
       "1    0.635172  0.038003  1.573987  ...  0.059630  0.120031  0.399223   \n",
       "2    0.126178  0.252569  0.889037  ...  0.195482  1.384532  0.522251   \n",
       "3   -0.775607  1.015937 -1.075737  ...  0.753417 -0.403380  0.087974   \n",
       "4   -2.854627  1.868818 -1.179460  ... -0.985540  0.419706 -0.610858   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "120 -0.047799 -1.285599 -1.671761  ... -0.657035 -1.615846 -0.404157   \n",
       "121 -0.893833 -0.435053 -3.232565  ... -0.421483 -1.478002 -0.518134   \n",
       "122  1.356583 -0.880754 -0.388243  ...  1.351073  1.798725  1.070365   \n",
       "123  0.487775 -1.031966  2.394362  ... -1.795643 -0.440259  0.731001   \n",
       "124  1.436368  1.178253  0.301407  ... -0.456698  0.408136  2.369287   \n",
       "\n",
       "          f95       f96       f97       f98       f99      f100      target  \n",
       "0   -0.625773 -0.907327 -0.800223  0.065892  0.271684 -0.201420  -45.587910  \n",
       "1    0.494030  0.197600  0.652323  0.916328 -1.556582 -0.370614  137.329473  \n",
       "2   -0.127655 -0.403076 -0.111509 -0.183150  0.977816 -1.171654  141.355900  \n",
       "3   -1.525572  2.404838  0.011863  0.994299 -2.152914 -0.213593  -65.882640  \n",
       "4    0.209534 -0.538048  0.164295 -0.984655 -0.598438 -0.887770 -333.409221  \n",
       "..        ...       ...       ...       ...       ...       ...         ...  \n",
       "120  0.810027 -1.333148  1.419036  0.144310  1.040058 -1.298104   82.055263  \n",
       "121 -2.248497  2.116012 -0.181734  0.043710 -1.572231 -0.903293   65.950817  \n",
       "122  0.086111 -0.777371  0.388376 -3.007632 -0.009289  0.084168   77.147045  \n",
       "123  0.341660  0.733548 -2.074486 -0.766864  0.041287 -0.423890  -13.136238  \n",
       "124 -0.502869 -0.756004 -0.822166  0.381353  0.464251  1.943529    1.627152  \n",
       "\n",
       "[125 rows x 101 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, разделите загруженный датасет на тренировочную и тестовую выборку. Для этого используйте функцию `train_test_split` из модуля `sklearn.model_selection` с параметрами `random_state=42` и `test_size=0.33`. Обучите линейную регрессию на тренировочных данных и оцените среднеквадратическую ошибку на тестовых данных. Один из вариантов линейной регрессии в `scikit-learn` представлен классом `Ridge` из `sklearn.linear_model`.\n",
    "Используйте параметр `random_state=42` в конструкторе класса при создании его экземпляра. Оценку среднеквадратичной ошибки проведите с помощью функции `mean_squared_error` из модуля `sklearn.metrics`. В качестве ответа `answer1` приведите это значение округлённое с точностью до двух знаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *РЕШЕНИЕ*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, random_state=42, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.160589</td>\n",
       "      <td>-1.520287</td>\n",
       "      <td>-0.834185</td>\n",
       "      <td>-0.227720</td>\n",
       "      <td>1.006730</td>\n",
       "      <td>-0.596895</td>\n",
       "      <td>0.176150</td>\n",
       "      <td>-0.361009</td>\n",
       "      <td>-0.109023</td>\n",
       "      <td>-0.420028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410518</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>-1.103184</td>\n",
       "      <td>0.612332</td>\n",
       "      <td>1.441942</td>\n",
       "      <td>2.927270</td>\n",
       "      <td>0.037542</td>\n",
       "      <td>-1.617801</td>\n",
       "      <td>-0.631437</td>\n",
       "      <td>-38.983516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.646905</td>\n",
       "      <td>-0.119559</td>\n",
       "      <td>1.380139</td>\n",
       "      <td>0.510535</td>\n",
       "      <td>0.905718</td>\n",
       "      <td>1.021963</td>\n",
       "      <td>0.726512</td>\n",
       "      <td>1.752292</td>\n",
       "      <td>-0.339530</td>\n",
       "      <td>-1.167757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.585975</td>\n",
       "      <td>0.960932</td>\n",
       "      <td>1.515414</td>\n",
       "      <td>0.562854</td>\n",
       "      <td>0.581723</td>\n",
       "      <td>-2.202913</td>\n",
       "      <td>-0.103812</td>\n",
       "      <td>0.207489</td>\n",
       "      <td>0.126313</td>\n",
       "      <td>-15.874280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.966917</td>\n",
       "      <td>1.601993</td>\n",
       "      <td>-1.417640</td>\n",
       "      <td>-0.461745</td>\n",
       "      <td>1.270529</td>\n",
       "      <td>-0.606963</td>\n",
       "      <td>-0.072347</td>\n",
       "      <td>0.587695</td>\n",
       "      <td>-1.358257</td>\n",
       "      <td>-0.551738</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.309732</td>\n",
       "      <td>-0.092166</td>\n",
       "      <td>-0.860524</td>\n",
       "      <td>2.368335</td>\n",
       "      <td>-0.006334</td>\n",
       "      <td>0.250514</td>\n",
       "      <td>-0.778587</td>\n",
       "      <td>-0.215568</td>\n",
       "      <td>0.713026</td>\n",
       "      <td>243.283563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.695538</td>\n",
       "      <td>-0.650024</td>\n",
       "      <td>-0.924233</td>\n",
       "      <td>-1.846188</td>\n",
       "      <td>-1.449645</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>-0.617253</td>\n",
       "      <td>-0.183197</td>\n",
       "      <td>-1.091701</td>\n",
       "      <td>0.575205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.383971</td>\n",
       "      <td>-0.387100</td>\n",
       "      <td>-1.517874</td>\n",
       "      <td>0.683569</td>\n",
       "      <td>1.795211</td>\n",
       "      <td>-0.478837</td>\n",
       "      <td>0.207267</td>\n",
       "      <td>-0.359769</td>\n",
       "      <td>0.408653</td>\n",
       "      <td>194.141296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-1.290561</td>\n",
       "      <td>0.566772</td>\n",
       "      <td>0.069370</td>\n",
       "      <td>-2.099356</td>\n",
       "      <td>-0.048965</td>\n",
       "      <td>0.447394</td>\n",
       "      <td>-0.375634</td>\n",
       "      <td>-1.153492</td>\n",
       "      <td>-0.448543</td>\n",
       "      <td>0.543391</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.027404</td>\n",
       "      <td>0.238555</td>\n",
       "      <td>1.534482</td>\n",
       "      <td>0.789920</td>\n",
       "      <td>1.325276</td>\n",
       "      <td>-0.739771</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>1.378470</td>\n",
       "      <td>0.503090</td>\n",
       "      <td>-217.605005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1        f2        f3        f4        f5        f6        f7  \\\n",
       "18  0.160589 -1.520287 -0.834185 -0.227720  1.006730 -0.596895  0.176150   \n",
       "42  0.646905 -0.119559  1.380139  0.510535  0.905718  1.021963  0.726512   \n",
       "36  0.966917  1.601993 -1.417640 -0.461745  1.270529 -0.606963 -0.072347   \n",
       "76  0.695538 -0.650024 -0.924233 -1.846188 -1.449645 -0.005596 -0.617253   \n",
       "53 -1.290561  0.566772  0.069370 -2.099356 -0.048965  0.447394 -0.375634   \n",
       "\n",
       "          f8        f9       f10  ...       f92       f93       f94       f95  \\\n",
       "18 -0.361009 -0.109023 -0.420028  ... -0.410518  0.034375 -1.103184  0.612332   \n",
       "42  1.752292 -0.339530 -1.167757  ...  2.585975  0.960932  1.515414  0.562854   \n",
       "36  0.587695 -1.358257 -0.551738  ... -1.309732 -0.092166 -0.860524  2.368335   \n",
       "76 -0.183197 -1.091701  0.575205  ... -0.383971 -0.387100 -1.517874  0.683569   \n",
       "53 -1.153492 -0.448543  0.543391  ... -1.027404  0.238555  1.534482  0.789920   \n",
       "\n",
       "         f96       f97       f98       f99      f100      target  \n",
       "18  1.441942  2.927270  0.037542 -1.617801 -0.631437  -38.983516  \n",
       "42  0.581723 -2.202913 -0.103812  0.207489  0.126313  -15.874280  \n",
       "36 -0.006334  0.250514 -0.778587 -0.215568  0.713026  243.283563  \n",
       "76  1.795211 -0.478837  0.207267 -0.359769  0.408653  194.141296  \n",
       "53  1.325276 -0.739771  0.808036  1.378470  0.503090 -217.605005  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>f100</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.392039</td>\n",
       "      <td>-0.664651</td>\n",
       "      <td>-1.422230</td>\n",
       "      <td>-1.941859</td>\n",
       "      <td>0.809265</td>\n",
       "      <td>-0.491562</td>\n",
       "      <td>-0.528947</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>-0.516847</td>\n",
       "      <td>0.084094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.619033</td>\n",
       "      <td>-0.443263</td>\n",
       "      <td>-1.353755</td>\n",
       "      <td>1.212129</td>\n",
       "      <td>-0.432295</td>\n",
       "      <td>0.880066</td>\n",
       "      <td>0.357661</td>\n",
       "      <td>-1.499181</td>\n",
       "      <td>-27.045030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.182161</td>\n",
       "      <td>0.091125</td>\n",
       "      <td>0.632216</td>\n",
       "      <td>0.604052</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>-0.333486</td>\n",
       "      <td>0.338976</td>\n",
       "      <td>0.818766</td>\n",
       "      <td>0.879014</td>\n",
       "      <td>-0.122436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.480574</td>\n",
       "      <td>-0.946491</td>\n",
       "      <td>0.281192</td>\n",
       "      <td>-0.504423</td>\n",
       "      <td>-1.932065</td>\n",
       "      <td>0.627680</td>\n",
       "      <td>2.206469</td>\n",
       "      <td>1.600098</td>\n",
       "      <td>-0.761941</td>\n",
       "      <td>-291.415251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.072681</td>\n",
       "      <td>-0.617642</td>\n",
       "      <td>0.893698</td>\n",
       "      <td>-0.409687</td>\n",
       "      <td>-1.880010</td>\n",
       "      <td>-0.139397</td>\n",
       "      <td>-0.755792</td>\n",
       "      <td>0.572390</td>\n",
       "      <td>-1.909356</td>\n",
       "      <td>0.443002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.649481</td>\n",
       "      <td>1.318302</td>\n",
       "      <td>-1.731201</td>\n",
       "      <td>-2.906988</td>\n",
       "      <td>-0.283139</td>\n",
       "      <td>-0.707626</td>\n",
       "      <td>-0.372319</td>\n",
       "      <td>-1.466785</td>\n",
       "      <td>0.313184</td>\n",
       "      <td>-14.484626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.522521</td>\n",
       "      <td>-0.216419</td>\n",
       "      <td>-0.335516</td>\n",
       "      <td>1.251947</td>\n",
       "      <td>-0.778309</td>\n",
       "      <td>-0.176134</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.976507</td>\n",
       "      <td>-1.688034</td>\n",
       "      <td>1.054621</td>\n",
       "      <td>...</td>\n",
       "      <td>2.305637</td>\n",
       "      <td>-0.600748</td>\n",
       "      <td>-0.455342</td>\n",
       "      <td>0.686774</td>\n",
       "      <td>-0.701957</td>\n",
       "      <td>0.268413</td>\n",
       "      <td>1.612868</td>\n",
       "      <td>1.896123</td>\n",
       "      <td>2.054092</td>\n",
       "      <td>18.230694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.179369</td>\n",
       "      <td>0.751099</td>\n",
       "      <td>-0.548200</td>\n",
       "      <td>-1.689183</td>\n",
       "      <td>0.028458</td>\n",
       "      <td>-0.262660</td>\n",
       "      <td>0.548320</td>\n",
       "      <td>-1.406815</td>\n",
       "      <td>0.960305</td>\n",
       "      <td>0.388312</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669070</td>\n",
       "      <td>0.462484</td>\n",
       "      <td>0.887504</td>\n",
       "      <td>2.184097</td>\n",
       "      <td>0.218534</td>\n",
       "      <td>0.537630</td>\n",
       "      <td>1.643378</td>\n",
       "      <td>0.506241</td>\n",
       "      <td>0.186416</td>\n",
       "      <td>-36.199008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "9    1.392039 -0.664651 -1.422230 -1.941859  0.809265 -0.491562 -0.528947   \n",
       "33  -0.182161  0.091125  0.632216  0.604052  0.998218 -0.333486  0.338976   \n",
       "62   0.072681 -0.617642  0.893698 -0.409687 -1.880010 -0.139397 -0.755792   \n",
       "25   0.522521 -0.216419 -0.335516  1.251947 -0.778309 -0.176134  0.001804   \n",
       "119 -1.179369  0.751099 -0.548200 -1.689183  0.028458 -0.262660  0.548320   \n",
       "\n",
       "           f8        f9       f10  ...       f92       f93       f94  \\\n",
       "9    0.856976 -0.516847  0.084094  ...  0.958816  0.619033 -0.443263   \n",
       "33   0.818766  0.879014 -0.122436  ... -0.480574 -0.946491  0.281192   \n",
       "62   0.572390 -1.909356  0.443002  ...  1.649481  1.318302 -1.731201   \n",
       "25   0.976507 -1.688034  1.054621  ...  2.305637 -0.600748 -0.455342   \n",
       "119 -1.406815  0.960305  0.388312  ...  1.669070  0.462484  0.887504   \n",
       "\n",
       "          f95       f96       f97       f98       f99      f100      target  \n",
       "9   -1.353755  1.212129 -0.432295  0.880066  0.357661 -1.499181  -27.045030  \n",
       "33  -0.504423 -1.932065  0.627680  2.206469  1.600098 -0.761941 -291.415251  \n",
       "62  -2.906988 -0.283139 -0.707626 -0.372319 -1.466785  0.313184  -14.484626  \n",
       "25   0.686774 -0.701957  0.268413  1.612868  1.896123  2.054092   18.230694  \n",
       "119  2.184097  0.218534  0.537630  1.643378  0.506241  0.186416  -36.199008  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of targets and number of penalties do not correspond: 8383 != 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-bafc0e20b619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \"\"\"\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                 return_intercept=False, check_input=False, **params)\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36m_ridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input)\u001b[0m\n\u001b[1;32m    440\u001b[0m         raise ValueError(\"Number of targets and number of penalties \"\n\u001b[1;32m    441\u001b[0m                          \u001b[0;34m\"do not correspond: %d != %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                          % (alpha.size, n_targets))\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_targets\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of targets and number of penalties do not correspond: 8383 != 1"
     ]
    }
   ],
   "source": [
    "model = ridge.fit(train, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [125, 42]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-03e044f8fe03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m    335\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 336\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sidio01/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 263\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [125, 42]"
     ]
    }
   ],
   "source": [
    "mean_squared_error(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вам предлагается стандартизовать данные используя `StandardScaler` из `sklearn.preprocessing`. По своей сути операция стандартизации в данном случае представляет из себя вычитание среднего из матрицы признаков и деление на среднеквадратическое отклонение. \n",
    "\n",
    "<font color  = \"red\">Важно:</font> Сначала следует разбить выборку на тренировочную и тестовую и лишь потом стандартизировать их по отдельности. Помните, что к тренировочной выборке мы должны применять метод `fit_transform()`, а к тестовой только `transform()`. Как изменилось качество на тестовых данных? В `answer2` запишите значение среднеквадратической ошибки, округлённое с точностью до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строка с ответами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mse 1: {0:.2f}\\nmse 2: {1:.2f}'.format(answer1, answer2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
